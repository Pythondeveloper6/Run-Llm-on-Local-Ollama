# Run LLM on Local Ollama

Learn how to run the open-source Language Model (LLM) using Ollama and how to connect to the Ollama server.

## Tutorial on YouTube:
- [Tutorial Link](https://youtu.be/Zgrjsv97hJU)

## Outline:
- Install Ollama
- How It Works
- Running Ollama
- Downloading Models
- Using Ollama in Terminal
- Ollama + Python
- Ollama + LangChain
- Ollama Chat UI
- Fixing Port Issues

![Image](https://github.com/Pythondeveloper6/Run-Llm-on-Local-Ollama/blob/main/screenshot.png)
